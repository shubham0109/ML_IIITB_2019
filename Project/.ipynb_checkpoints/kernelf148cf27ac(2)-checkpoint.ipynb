{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import calendar\n",
    "from datetime import timedelta\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data consists of 55M rows, taking 400K rows initially\n",
    "train = pd.read_csv(\"/kaggle/input/iiitb2019nyctaxifare/TrainTest/train.csv\", nrows = 2000000)\n",
    "test = pd.read_csv(\"/kaggle/input/iiitb2019nyctaxifare/TrainTest/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of datetime\n",
    "def change_datetime_format(data):\n",
    "    data['pickup_datetime']=pd.to_datetime(data['pickup_datetime'],format='%Y-%m-%d %H:%M:%S UTC')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the datetime\n",
    "def split_datetime(data):\n",
    "    data['pickup_date']= data['pickup_datetime'].dt.date\n",
    "    data['pickup_day']=data['pickup_datetime'].apply(lambda x:x.day)\n",
    "    data['pickup_hour']=data['pickup_datetime'].apply(lambda x:x.hour)\n",
    "    data['pickup_day_of_week']=data['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])\n",
    "    data['pickup_month']=data['pickup_datetime'].apply(lambda x:x.month)\n",
    "    data['pickup_year']=data['pickup_datetime'].apply(lambda x:x.year)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers in latitude and longitude\n",
    "def remove_outliers(data):\n",
    "    \n",
    "    misplaced_locations_index = []\n",
    "\n",
    "    for i, val in enumerate(zip(data.pickup_latitude,data.dropoff_latitude,data.pickup_longitude,data.dropoff_longitude)):\n",
    "\n",
    "        #print(val)\n",
    "        #break\n",
    "\n",
    "        lat1,lat2,lon1,lon2 = val\n",
    "        #co_ords1 = (lat1, lon1)\n",
    "        #co_ords2 = (lat2, lon2)\n",
    "\n",
    "        if lat1 < 40.5 or lat1 > 41.8 or lat2 < 40.5 or lat2 > 41.8 or lon1 < -74.5 or lon1 > -72.8 or lon2 < -74.5 or lon2 > -72.8:\n",
    "            misplaced_locations_index.append(i)\n",
    "\n",
    "\n",
    "    data = data.drop(misplaced_locations_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null(data):\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg_pass_count(data):\n",
    "    data = data.drop(data[data['passenger_count'] <= 0 ].index.tolist())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg_fare_amount(data):\n",
    "    data = data.drop(data[data['fare_amount'] <= 0].index.tolist())\n",
    "    data = data[data['fare_amount'] <=8]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate trip distance in miles\n",
    "def distance(lat1, lat2, lon1,lon2):\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(data):\n",
    "    data['trip_distance']=data.apply(lambda row:distance(row['pickup_latitude'],row['dropoff_latitude'],row['pickup_longitude'],row['dropoff_longitude']),axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us encode day of the week to numbers\n",
    "def encodeDays(day_of_week):\n",
    "    day_dict={'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6}\n",
    "    return day_dict[day_of_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickupday_encode(data):\n",
    "    data['pickup_day_of_week']=data['pickup_day_of_week'].apply(lambda x:encodeDays(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    data.drop(columns=['key','pickup_datetime','pickup_date'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "def cleandata(data,flag = True):\n",
    "    if flag == True:\n",
    "        data = change_datetime_format(data)\n",
    "        data = split_datetime(data)\n",
    "        data = remove_outliers(data)\n",
    "        data = remove_null(data)\n",
    "        data = remove_neg_pass_count(data)\n",
    "        data = remove_neg_fare_amount(data)\n",
    "        data = calc_distance(data)\n",
    "        data = pickupday_encode(data)\n",
    "        data = drop_columns(data)\n",
    "    else:\n",
    "        data = change_datetime_format(data)\n",
    "        data = split_datetime(data)\n",
    "        data = pickupday_encode(data)\n",
    "        data = calc_distance(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cleandata(train)\n",
    "test = cleandata(test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDataForModelling(data,target,is_train=True,split=0.3):\n",
    "    data_1=data\n",
    "    # One hot Encoding\n",
    "    data_1=pd.get_dummies(data_1)\n",
    "    if is_train==True:\n",
    "        X=data_1.drop([target],axis=1)\n",
    "        y=data_1[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=split,random_state=123)\n",
    "        \n",
    "        print(\"Shape of Training Features\",X_train.shape)\n",
    "        print(\"Shape of Validation Features \",X_test.shape)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        print (\"Shape of Test Data\",data_1.shape)\n",
    "        return data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=processDataForModelling(train,'fare_amount',is_train=True,split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_fare=round(np.mean(y_train),2)\n",
    "#avg_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "#baseline_pred=np.repeat(avg_fare,test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"p = pd.DataFrame(baseline_pred)\n",
    "datasets = pd.concat([test['key'],p[0]],axis=1)\n",
    "datasets.columns = ['key', 'fare_amount']\n",
    "datasets.to_csv('submission1.csv',index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_value = test['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = ['pickup_date', 'key','pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(method = 'ffill',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in test.columns:\n",
    " #   print(i,test[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linearRegressor = LinearRegression()\n",
    "#linearRegressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = linearRegressor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''p = pd.DataFrame(y_pred)\n",
    "datasets = pd.concat([key_value,p[0]],axis=1)\n",
    "datasets.columns = ['key', 'fare_amount']\n",
    "datasets.to_csv('submission2.csv',index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from IPython.display import FileLink\n",
    "FileLink(r'submission2.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = pd.read_csv(\"/kaggle/working/submission2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data=lgb.Dataset(X_train,label=y_train)\n",
    "param = {'num_leaves':31, 'num_trees':5000,'objective':'regression'}\n",
    "param['metric'] = 'l2_root'\n",
    "num_round=5000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)\n",
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = lgb_bst.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(lgb_pred)\n",
    "datasets = pd.concat([key_value,p[0]],axis=1)\n",
    "datasets.columns = ['key', 'fare_amount']\n",
    "datasets.to_csv('submission4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'submission4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
